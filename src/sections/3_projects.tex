\sectionTitle{Selected Research Projects}{}

\begin{projects}
	\project{AI-Powered Design Generation and Optimization}{Apr'23 - Present}{
		\textit{Colleague: \href{https://scholar.google.com/citations?user=LAGYWIoAAAAJ}{Mr. Atsuki Osanai}, \href{https://scholar.google.com/citations?user=IMg7jAwAAAAJ}{Dr. Ryota Yoshihashi}}
	}
	{
		\begin{itemize}
			\setlength\itemsep{0.3em}
			\item Working on advanced AI techniques for design and layout generation to assist designers, focusing on visual awareness and self-correction mechanisms that enhance designer productivity and improve the quality of generated designs.
			\item Developed VASCAR, a content-aware layout generation approach that enables large vision-language models to iteratively refine layouts with reference to rendered images.~ [\href{https://arxiv.org/abs/2412.04237}{\small{\arxivSymbol}}] ~ {\small{\lbrack\textbf{{arXiv'24}}\rbrack}}
			\item Developed Layout-Corrector, a layout-assessment module that addresses the layout sticking phenomenon in discrete diffusion models.~ [\href{https://github.com/line/Layout-Corrector}{\small{\arxivSymbol}}] ~ {\small{\lbrack\textbf{{ECCV'24}}\rbrack}}
		\end{itemize}
	}
	\project{Multi-modal Deep Learning Models for Supporting Ad Creative Operations}{Aug'18 - Present}
	{
		\textit{Advisors:  \href{https://scholar.google.com/citations?user=LoZ7VeYAAAAJ}{Dr. Yoshifumi Seki}, \href{https://iyatomi-lab.info/english/people/2013-6-8}{Prof. Hitoshi Iyatomi}}
	}
	{
		\begin{itemize}
			\setlength\itemsep{0.3em}
			\item Working on supporting the operations of effective/ineffective online ad creatives based on recent machine learning.
			\item Developed a framework to support the creation of effective ad creatives.~ [\href{https://github.com/shunk031/Multi-task-Conditional-Attention-Networks}{\small{\githubSymbol}}] ~ {\small{\lbrack\textbf{{KDD'19}}\rbrack}}
			\item Developed a framework to support the discontinuation of ineffective ad creatives.~ [\href{https://www.mdpi.com/2076-3417/12/7/3594}{\small{\websiteSymbol}}] ~ {\small{\lbrack\textbf{{Appl. Sci'22}}\rbrack}}
		\end{itemize}
	}
	\project{Robust and Interpretable Deep Learning Models}{Apr'19 - Present}
	{
		\textit{Advisor:  \href{https://iyatomi-lab.info/english/people/2013-6-8}{Prof. Hitoshi Iyatomi}}
	}
	{
		\begin{itemize}
			\setlength\itemsep{0.3em}
			\item Working on interpretable deep learning models, especially for natural language processing (NLP). Focusing on the vulnerability of perturbations in the attention mechanisms, developed new training technique to overcome the weakness, making attention mechanisms more robust and interpretable.
			\item Developed a general training technique to overcome the vulnerability to perturbations in attention mechanisms, inspired by adversarial training which is a powerful regularization technique for enhancing the robustness of deep learning models.~ [\href{http://shunk031.github.io/attention-meets-perturbation/}{\small{\websiteSymbol}}] ~ {\small{\lbrack\textbf{{IEEE Access'21}}\rbrack}}
			\item Developing an extension of the above method to semi-supervised learning, with additional use of unlabeled data to further improve robustness and interpretability of the model.~ {\small{\lbrack\textbf{{Springer APIN'22}}\rbrack}}
		\end{itemize}
	}
	% \project{Glyph-aware NLP for Effectively Modeling Asian Languages}{Apr'17 - Mar'23}
	% {
	% 	\textit{Advisor:  \href{https://iyatomi-lab.info/english/people/2013-6-8}{Prof. Hitoshi Iyatomi}}
	% }
	% {
	% 	\begin{itemize}
	% 		\setlength\itemsep{0.3em}
	% 		\item Working on establishing effective NLP for Asian languages that have visual meanings in their characters.
	% 		\item Developed a glyph-aware disentangled embedding and semantic sub-character augmentation, a data augmentation method using its characteristics.~ [\href{https://github.com/IyatomiLab/GDCE-SSA}{\small{\githubSymbol}}] ~ {\small{\lbrack\textbf{{AACL-IJCNLP'20 SRW}}\rbrack}}
	% 		\item Developed a new end-to-end model composed character encoder - text classifier architecture for visually unique characters. This NLP model, in which character images are input, can be extended with data augmentation used in computer vision field.~ For Japanese: [\href{https://github.com/IyatomiLab/CE-CLCNN}{\small{\githubSymbol}}] ~ {\small{\lbrack\textbf{{AIPRW'18}}\rbrack}}; ~ For Arabic: [\href{https://github.com/mahmouddaif/AraDIC}{\small{\githubSymbol}}] ~ {\small{\lbrack\textbf{{ACL'20 SRW}}\rbrack}}
	% 	\end{itemize}
	% }
\end{projects}

